{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is referenced from https://github.com/dawenl/vae_cf (Variational autoencoders for collaborative filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from scipy import sparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainPath = 'C:\\\\Users\\\\nizhe\\\\Desktop\\\\python code\\\\ml-20m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_original = pd.read_csv(os.path.join(mainPath, 'ratings.csv'), header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(raw_data_original):\n",
    "    '''\n",
    "    Drop user count less than 5, and movie count less than 0\n",
    "    '''\n",
    "    raw_data = raw_data_original[raw_data_original['rating'] > 3.5].drop('timestamp', axis = 1)\n",
    "    user_count_df = raw_data.groupby('userId').count().reset_index()[['userId', 'rating']].rename(columns = {'rating' : 'count'})\n",
    "    user_count_df = user_count_df[user_count_df['count'] >= 5]\n",
    "    movie_count_df = raw_data.groupby('movieId').count().reset_index()[['movieId', 'rating']].rename(columns = {'rating' : 'count'})\n",
    "    movie_count_df = movie_count_df[movie_count_df['count'] >= 0]\n",
    "    \n",
    "    result_df = raw_data.merge(user_count_df, on = 'userId').drop('count', axis = 1).merge(movie_count_df, on = 'movieId').drop('count', axis = 1)\n",
    "    \n",
    "    return result_df, user_count_df['count'], movie_count_df['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = preprocessing(raw_data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(user_activity)\n",
    "n_heldout_users = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index # the entire users without duplicates\n",
    "    \n",
    "np.random.seed(98765)\n",
    "unique_uid = unique_uid[np.random.permutation(unique_uid.size)] # shuffle\n",
    "\n",
    "# split all the users in 3 parts\n",
    "tr_users = unique_uid[ : (n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2) : (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users) : ]\n",
    "\n",
    "train_df = raw_data.loc[raw_data['userId'].isin(tr_users)]\n",
    "\n",
    "unique_sid = pd.unique(train_df['movieId']) # the entire items from tr without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test_prop = 0.2):\n",
    "    \n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype = 'bool')\n",
    "            idx[np.random.choice(n_items_u, size = int(test_prop * n_items_u), replace = False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "    data_tr = pd.concat(tr_list)    \n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_plays = raw_data[raw_data['userId'].isin(vd_users) & raw_data['movieId'].isin(unique_sid)]\n",
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users) & raw_data['movieId'].isin(unique_sid)]\n",
    "\n",
    "vad_plays_tr, vad_plays_te = train_test_split(vad_plays)\n",
    "test_plays_tr, test_plays_te = train_test_split(test_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = numerize(train_df)\n",
    "vad_tr = numerize(vad_plays_tr)\n",
    "vad_te = numerize(vad_plays_te)\n",
    "test_tr = numerize(test_plays_tr)\n",
    "test_te = numerize(test_plays_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
