{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from utils import *\n",
    "from WAE import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainPath = 'C:\\\\Users\\\\nizhe\\\\Desktop\\\\python code\\\\ml-20m'\n",
    "data_dir = '\\\\data'\n",
    "unique_sid, n_items, train_data, vad_data_tr, vad_data_te = load_data(mainPath + data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "batch_size_vad = 500\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = list(range(N_vad))\n",
    "total_anneal_steps = 200000\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dims = [300, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "wae = WAE(p_dims, random_seed = 12345)\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = wae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype = tf.float64, shape = None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "\n",
    "recall_var = tf.Variable(0.0)\n",
    "recall_dist_var = tf.placeholder(dtype = tf.float64, shape = None)\n",
    "recall_summary = tf.summary.scalar('recall_at_k_validation', recall_var)\n",
    "recall_dist_summary = tf.summary.histogram('recall_at_k_hist_validation', recall_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary, recall_summary, recall_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: \\log\\ml-20m\\wae\\I-600-200-600-I2019-04-14 23-56-22-962512\n",
      "ckpt directory: \\chkpt\\ml-20m\\wae\\I-600-200-600-I2019-04-14 23-56-23-576276\n"
     ]
    }
   ],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in wae.dims[1:-1]]))\n",
    "\n",
    "log_dir = mainPath + '\\\\log\\\\ml-20m\\\\wae\\\\{}'.format(arch_str) + str(datetime.datetime.today()).replace(':', '-').replace('.', '-')\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph = tf.get_default_graph())\n",
    "\n",
    "ckpt_dir = mainPath + '\\\\chkpt\\\\ml-20m\\\\wae\\\\{}'.format(arch_str) + str(datetime.datetime.today()).replace(':', '-').replace('.', '-')\n",
    "if not os.path.isdir(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)    \n",
    "print(\"ckpt directory: %s\" % ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "recall_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    best_ndcg = -np.inf\n",
    "    \n",
    "    update_count = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        print (epoch)\n",
    "        # train for one epoch\n",
    "        print ('begin training...')\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx : end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            \n",
    "            feed_dict = {wae.input_ph: X, \n",
    "                         wae.keep_prob_ph: 0.6, \n",
    "                         wae.batch_size : X.shape[0],\n",
    "                         wae.anneal_ph: min(anneal_cap, 1. * update_count / total_anneal_steps)} \n",
    "            \n",
    "            sess.run(train_op_var, feed_dict = feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                try:\n",
    "                    summary_train = sess.run(merged_var, feed_dict = feed_dict)\n",
    "                    summary_writer.add_summary(summary_train, global_step = epoch * batches_per_epoch + bnum) \n",
    "                except tf.errors.InvalidArgumentError:\n",
    "                    pass\n",
    "            \n",
    "            update_count += 1\n",
    "            \n",
    "        print ('begin evaluating...')\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        recall_dist = []\n",
    "        \n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx : end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict = {wae.input_ph : X} )\n",
    "            \n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            \n",
    "            ndcg_tmp, recall_tmp = get_NDCG_Recall(pred_val, vad_data_te[idxlist_vad[st_idx : end_idx]], k_ndcg = 100, k_rcall = 50)\n",
    "            \n",
    "            ndcg_dist.append(ndcg_tmp)\n",
    "            recall_dist.append(recall_tmp)\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        \n",
    "        recall_dist = np.concatenate(recall_dist)\n",
    "        recall_ = recall_dist.mean()\n",
    "        recall_vad.append(recall_)\n",
    "        \n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict = {ndcg_var: ndcg_, ndcg_dist_var : ndcg_dist,\n",
    "                                                               recall_var: recall_, recall_dist_var : recall_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(ckpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.plot(recall_vad)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation NDCG@100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"ndcg_100.csv\", ndcgs_vad, delimiter=\",\", fmt='%s', header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"recall_100.csv\", recall_vad, delimiter=\",\", fmt='%s', header=header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
